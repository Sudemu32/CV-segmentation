{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b9f4b41-7383-4701-93af-6bcfd8d72950",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "import torch.nn.functional as F\n",
    "from matplotlib import pyplot as plt\n",
    "import threading\n",
    "# Загрузка модели PyTorch\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "state_dict = torch.load('C:/Users/work/FILTERS/Models/model_weave_1024_x_circ_512_ep14_12.pth')['model_state_dict']\n",
    "model = UNet(3)\n",
    "model.load_state_dict(state_dict, strict=True)\n",
    "model.eval()  # Переводим модель в режим оценки\n",
    "\n",
    "# Трансформации для входного изображения\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize((512, 512)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "# Функция для предобработки кадра\n",
    "def preprocess_frame(frame):\n",
    "    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    frame = transform(frame)\n",
    "    frame = frame.unsqueeze(0)  # Добавляем размерность батча\n",
    "    return frame\n",
    "\n",
    "# Функция для постобработки маски\n",
    "def postprocess_mask(mask):\n",
    "    \n",
    "    \n",
    "    mask[mask<0.76] = 0\n",
    "    \n",
    "    return mask\n",
    "\n",
    "# Функция для наложения маски\n",
    "def overlay_mask_on_frame(frame, mask, alpha=0.5):\n",
    "    mask = cv2.resize(mask, (frame.shape[1], frame.shape[0]))\n",
    "    color_mask = np.zeros_like(frame)\n",
    "    color_mask[mask == 255] = [0, 0, 255]  # Красный цвет для сегментации\n",
    "    overlayed = cv2.addWeighted(frame, 1 - alpha, color_mask, alpha, 0)\n",
    "    return overlayed\n",
    "\n",
    "# Обработка видео\n",
    "def process_video(input_video_path, output_video_path):\n",
    "    cap = cv2.VideoCapture(input_video_path)\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    \n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    out = cv2.VideoWriter(output_video_path, fourcc, fps, (width, height))\n",
    "    \n",
    "    with torch.no_grad():  # Отключаем вычисление градиентов\n",
    "        while cap.isOpened():\n",
    "            start_time = time.time()\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "                \n",
    "            # Предобработка и преобразование в тензор PyTorch\n",
    "            input_tensor = preprocess_frame(frame)\n",
    "            \n",
    "            # Передаем данные через модель\n",
    "            if torch.cuda.is_available():\n",
    "                input_tensor = input_tensor.cuda()\n",
    "            \n",
    "            output = model(input_tensor)\n",
    "            output = F.softmax(output, dim=1)\n",
    "            # Преобразуем выход модели в маску\n",
    "            mask = output.squeeze().cpu().numpy()  # Удаляем размерности батча и каналов\n",
    "            \n",
    "            # Постобработка и наложение маски\n",
    "            mask = postprocess_mask(mask[1])\n",
    "            \n",
    "            result_frame = overlay_mask_on_frame(frame, mask)\n",
    "            plt.imshow(result_frame)\n",
    "            # Сохранение и отображение\n",
    "            \n",
    "            out.write(result_frame)\n",
    "            elapsed_time = time.time() - start_time  \n",
    "            time.sleep(max(0, 1 - elapsed_time))\n",
    "            \n",
    "           \n",
    "    \n",
    "    cap.release()\n",
    "    out.release()\n",
    "    \n",
    "\n",
    "# Пример использования\n",
    "input_video = '4_3.mp4'\n",
    "output_video = 'output_segmented.mp4'\n",
    "process_video(input_video, output_video)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4fcaa51-e3b2-4e72-a869-c79845bd4b4c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
